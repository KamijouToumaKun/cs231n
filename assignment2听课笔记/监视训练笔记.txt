监视训练，并在训练过程中调整超参数（babysit，即照看训练过程）

检查BUG
比如，一开始的权重都是随机的
假如要做一个softmax的10分类，那么一开始选对的概率就应该约为log(1/10)
softmax loss = ∑yj log sj for each j（每个类别）
sj表示这个样本属于第j个类别的概率，为1/10
y是一个1*T的向量，里面的T个值，而且只有真实标签的1个值是1，其他T-1个值都是0
那么可以在初始化参数时检查，loss function 应该约为 -log(1/10) = log10 = 2.3
当然，如果损失函数里面还有正则化项，那么初始值应该大于2.3，比如为3.0之类的

sanity check：对于一个小数据集（比如只从CIFAR-10中取20个数据）
取消掉正则化项目，看训练能不能完全拟合：loss降到0（不仅是准确率上升到1）

学习率：首先该调整的参数！！！
1、学习率太小（比如1e-6）的时候，最初时每个epoch过后，loss基本不变化（2.3左右）
但是，准确率却很快地上升到了20%？？？
学习率过小，学习更多轮也是可以的，但是完全没有必要
因为权重参数向着正确的方向有了轻微的变化
而只要对的选项的得分比错的选项的得分高一点点，就能选对了：早期就是可能有这样的突变
2、学习率太大（比如1e6）的时候，loss = Nan（类似拼音的读法“难”）
就算是3e-3，也很大：loss = inf
（此处有图）
3、就是这样，分散地选择一些超参数，然后只训练几个epoch就够了：loss没有变化，或者nan？
对各个超参数进行逐个检验，注意使用交叉验证，在验证集上验证
然后确定，最好的学习率应该介于（1e-5，1e-3）之间

其他超参数：学习率的衰减率（decay），模型大小（batch大小？）
最好让W的更新部分和W本身的比为1e-3左右
这就涉及到了二阶的超参数了……不要一上来就盲目搞decay

然后再细分，做上千个循环的精确检验
细分不是线性均匀的的，而是取对数后均匀采样。因为学习率是乘在结果上面的
如果中途loss已经变得非常大了（例如，变成了初始的3倍），可以直接停止并放弃该参数

检查正则化参数的问题
如果训练集和验证集之间差距较大：训练集的准确率还在不断上升，而验证集的准确率不变了
就是过拟合了，需要加大正则化参数

如果对各个超参数都是均匀取样，这叫做grid layout
更好的选择是random layout（见图）
因为，超参数之间也并不是独立的（一般学习率还是比较独立的，优先确定它）
老实说，为了在空间中找一组表现最好的超参数，本身也是一个最优解问题！！！
应该用强化学习来求解吧？？？

学习率衰减（decay）
在学习初期你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。
有很多种衰减的方法，比如指数衰减；你有多个选择，来控制学习率 α
你可能会想 哇 好多超参数，究竟我应该做哪一个选择？我觉得 现在担心为时过早。
